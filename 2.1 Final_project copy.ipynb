{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature： Free Shipping Bar with 50$ Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import Packages and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File 1.3 AB Visit Data Test1_2.csv does not exist: '1.3 AB Visit Data Test1_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6d8f02161d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_Test_Overall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'1.3 AB Visit Data Test1_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'1.2 AB Rev Data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_categorymap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'1.1 AB Category Mapping.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File 1.3 AB Visit Data Test1_2.csv does not exist: '1.3 AB Visit Data Test1_2.csv'"
     ]
    }
   ],
   "source": [
    "##import data\n",
    "# 1.1 AB Category: https://drive.google.com/file/d/1F7-jE-fOPEg-ytnbwG5YfsrbsoHau6u2/view?usp=sharing\n",
    "# 1.2 AB Rev Data: https://drive.google.com/file/d/1CQjswN9xbipO6x-Ec3MnGcc7eSbEjFCE/view?usp=sharing\n",
    "# 1.3 AB Visit Data Test1_2: https://drive.google.com/file/d/1L8VRtjmGXfY_3HCJSKYlW1_-dRug5LKJ/view?usp=sharing\n",
    "df_Test_Overall = pd.read_csv(r'1.3 AB Visit Data Test1_2.csv')\n",
    "df_rev = pd.read_csv(r'1.2 AB Rev Data.csv')\n",
    "df_categorymap=pd.read_csv(r'1.1 AB Category Mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test_Overall.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filter data for test2, and check traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=df_Test_Overall[df_Test_Overall['testid']==2]\n",
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test2 has 6,870,668 rows of data(6 million)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the number of control and var\n",
    "df_Test.drop_duplicates(['ControlGroup','SessionID']).groupby(['ControlGroup'])['SessionID'].count()\n",
    "#yes,they are almost equal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many traffic are in our test(2) each day\n",
    "df_Test.drop_duplicates(['Date','SessionID']).groupby(['Date'])['SessionID'].count()\n",
    "#and we found out the 4 days at the beginning and the last day our traffic have some problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to exclude the date for these days from the original test dataset for test2.\n",
    "df_Test=df_Test[pd.to_datetime(df_Test['Date'])>pd.to_datetime('2019-06-17')]\n",
    "df_Test=df_Test[pd.to_datetime(df_Test['Date'])<pd.to_datetime('2019-07-12')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how our data looks now\n",
    "df_Test.drop_duplicates(['Date','SessionID']).groupby(['Date'])['SessionID'].count()\n",
    "#yeahee!we've exclude them succussfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Analyze metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the customer behavior on session level, but we will automate this part with customer level later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the counts of session_id for each test group and store the result into a new pandas dataframe named df_result\n",
    "df_Result=pd.DataFrame(df_Test.drop_duplicates(['SessionID','ControlGroup']).groupby('ControlGroup')['SessionID'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=['Bounced','SawProduct','AddedToCart','ReachedCheckout','Converted']\n",
    "#create loop to get all the counts of \"1\" for each metrics\n",
    "for metric in metrics:\n",
    "    #get the column of \"1s\" for that metric,then count the number of it,then store the row of result number as a.\n",
    "    a=df_Test[df_Test[metric]==1].drop_duplicates(['SessionID','ControlGroup']).groupby('ControlGroup')['SessionID'].count()\n",
    "    #define the column name as that metric name\n",
    "    a.name=metric\n",
    "    #join each result on the df_result dataframe we've crested above.\n",
    "    df_Result=df_Result.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a z_test calculation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_test_calculator(df,denominator,numerator):\n",
    "    #df: dataframe containing the result (absolute counts)\n",
    "    #denominator: str\n",
    "    #numerator:str\n",
    "    \n",
    "    #get the data [1,]or[0,] is control or variation,denominator and numerator is our imput,\n",
    "    #normally it should be a count of total number, and a count of the metric number we observed.\n",
    "    control_denominator=df.loc[1,denominator]\n",
    "    var_denominator=df.loc[0,denominator]\n",
    "    control_numerator=df.loc[1,numerator]\n",
    "    var_numerator=df.loc[0,numerator]    \n",
    "    \n",
    "    #caculate the Rate: simply do 2 divide\n",
    "    control_rate=control_numerator/control_denominator\n",
    "#     print(control_numerator)\n",
    "#     print(control_denominator)\n",
    "    var_rate=var_numerator/var_denominator\n",
    "    \n",
    "    #calculate the STD: sd=p(1-p)/N 再开根号\n",
    "#     print(control_rate)\n",
    "    control_sd=math.sqrt(control_rate*(1-control_rate)/control_denominator)\n",
    "    \n",
    "    var_sd=math.sqrt(var_rate*(1-var_rate)/var_denominator)\n",
    "    \n",
    "    #z score =两个rate的差值/control和variation的平均标准差\n",
    "    #control和variation的平均标准差=control的标准差的平方+variation的标准差的平方 再开根号\n",
    "    \n",
    "    z_score=(control_rate-var_rate)/math.sqrt(pow(control_sd,2)+pow(var_sd,2))\n",
    "    \n",
    "    \n",
    "    #p value python有方法可以直接找到pvalue，simply input the absolute value of z_score.\n",
    "    p_value=scipy.stats.norm.sf(abs(z_score))\n",
    "    \n",
    "    \n",
    "    #lift simple subtract and divide\n",
    "    perc_lift=(var_rate-control_rate)/control_rate\n",
    "    abs_lift=(var_rate-control_rate)\n",
    "    \n",
    "    return (p_value,perc_lift,abs_lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Calculation part, calculate all metrics on both levels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_types=['SessionID','CusID']\n",
    "dic_final={}\n",
    "metrics=['Bounced','SawProduct','AddedToCart','ReachedCheckout','Converted']\n",
    "\n",
    "for user_type in user_types:\n",
    "    df_Result_any=pd.DataFrame(df_Test.drop_duplicates([user_type,'ControlGroup']).groupby('ControlGroup')[user_type].count())\n",
    "    \n",
    "    for metric in metrics:\n",
    "        a=df_Test[df_Test[metric]==1].drop_duplicates([user_type,'ControlGroup']).groupby('ControlGroup')[user_type].count()\n",
    "        a.name=metric\n",
    "        df_Result_any=df_Result_any.join(a)\n",
    "\n",
    "    KPIs=[(user_type,'Bounced'),\n",
    "          (user_type,'SawProduct'),\n",
    "          (user_type,'AddedToCart'),\n",
    "          (user_type,'ReachedCheckout'),\n",
    "          (user_type,'Converted'),\n",
    "          ('AddedToCart','ReachedCheckout'),\n",
    "          ('ReachedCheckout','Converted'),\n",
    "          ('AddedToCart','Converted')]\n",
    "\n",
    "    for index in df_Result_any.index:\n",
    "        j=0\n",
    "        if index!=1:\n",
    "            df_each_group=df_Result_any\n",
    "\n",
    "            df_final=pd.DataFrame()\n",
    "\n",
    "            for i in KPIs:\n",
    "                result=z_test_calculator(df_each_group,i[0],i[1])\n",
    "                df_final.loc[j,'denominator']=i[0]\n",
    "                df_final.loc[j,'numerator']=i[1]\n",
    "                df_final.loc[j,'p_value']=result[0]\n",
    "                df_final.loc[j,'perc_lift']=result[1]\n",
    "                df_final.loc[j,'abs_lift']=result[2]\n",
    "                j=j+1\n",
    "            dic_final[user_type]=df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check what does df_Result_any look like now, should be for customer level now, because it's the last item in user_types list.\n",
    "df_Result_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the value for key \"CusID\", it should be results for customer level\n",
    "dic_final['CusID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export result into excel file, in multiple sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('3.1 Final_data_Test2.xlsx')\n",
    "for key in dic_final.keys():\n",
    "    dic_final[key].to_excel(writer, sheet_name=key)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-calculate everything in different cuts(different categories in item purchased, platform using, and visitor type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data = df_Test.copy()\n",
    "dic_final_cuts_usertype = {}\n",
    "user_types = ['SessionID','CusID']\n",
    "cuts = ['CategoryID', 'PlatformID','VisitorTypeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_type in user_types:\n",
    "    print(user_type)\n",
    "    for cut in cuts:\n",
    "        print(cut)\n",
    " \n",
    "        for p in set(df_test_data[cut]):\n",
    "\n",
    "            df_Test_cut = df_test_data[df_test_data[cut]==p]\n",
    "            df_Result_any1 = pd.DataFrame(df_Test_cut.drop_duplicates([user_type,'ControlGroup']).groupby('ControlGroup')[user_type].count())\n",
    "\n",
    "            metrics = ['Bounced','SawProduct','AddedToCart','ReachedCheckout','Converted']\n",
    "            for metric in metrics:\n",
    "                a = df_Test_cut[df_Test_cut[metric]==1].drop_duplicates([user_type,'ControlGroup']).groupby('ControlGroup')[user_type].count()\n",
    "                a.name = metric\n",
    "                df_Result_any1 = df_Result_any1.join(a)\n",
    "                print(df_Result_any1)\n",
    "\n",
    "\n",
    "            KPIs=[(user_type,'Bounced'),\n",
    "          (user_type,'SawProduct'),\n",
    "          (user_type,'AddedToCart'),\n",
    "          (user_type,'ReachedCheckout'),\n",
    "          (user_type,'Converted'),\n",
    "          ('AddedToCart','ReachedCheckout'),\n",
    "          ('ReachedCheckout','Converted'),\n",
    "          ('AddedToCart','Converted')]\n",
    "\n",
    "            for index in df_Result_any1.index:\n",
    "                j=0\n",
    "                #reset the index\n",
    "                if index!=1:\n",
    "                    df_each_group = df_Result_any1\n",
    "                    df_final=pd.DataFrame()\n",
    "\n",
    "\n",
    "                    for i in KPIs:\n",
    "                        result=z_test_calculator(df_each_group,i[0],i[1])\n",
    "                        df_final.loc[j,'denominator']=i[0]\n",
    "                        df_final.loc[j,'numerator'] = i[1]\n",
    "                        df_final.loc[j,'p_value'] = result[0]\n",
    "                        df_final.loc[j,'perc_lift'] = result[1]\n",
    "                        df_final.loc[j,'abs_lift']= result[2]\n",
    "                        j=j+1\n",
    "\n",
    "                    dic_final_cuts_usertype[user_type+'_'+cut+str(p)]= df_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_final_cuts_usertype['SessionID_CategoryID2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export result into excel file, in multiple sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel contain all the possible cuts\n",
    "writer = pd.ExcelWriter('3.2 Final_cuts_data_Test2.xlsx')\n",
    "for key in dic_final_cuts_usertype.keys():\n",
    "    dic_final_cuts_usertype[key].to_excel(writer, sheet_name=key)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyze revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cusid=df_Test_Overall[['SessionID','ControlGroup','CusID','CategoryID','VisitorTypeID']]\n",
    "df_cusid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Rev=pd.merge(df_rev,df_cusid, on = ['SessionID','ControlGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Rev=df_Rev[df_Rev['testid']==2]\n",
    "df_Rev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Rev.drop_duplicates(['ControlGroup','SessionID']).groupby(['ControlGroup'])['SessionID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_Rev=df_Rev[df_Rev['ControlGroup']==1]['TotalRevenue'].array\n",
    "Control_Rev\n",
    "Var_Rev=df_Rev[df_Rev['ControlGroup']==0]['TotalRevenue'].array\n",
    "Control_Rev\n",
    "Var_Rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1=np.percentile(Control_Rev,95)\n",
    "P2=np.percentile(Var_Rev,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(Control_Rev,Var_Rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_test_calculator_continuous(df,denominator,numerator,numerator_sq):\n",
    "    #df: dataframe containing the result (absolute counts)\n",
    "    #denominator: str\n",
    "    #numerator:str\n",
    "    #numerator_sq:str\n",
    "    \n",
    "    #get the data\n",
    "    control_denominator=df.loc[1,denominator]\n",
    "    var_denominator=df.loc[0,denominator]\n",
    "    control_numerator=df.loc[1,numerator]\n",
    "    var_numerator=df.loc[0,numerator]    \n",
    "    \n",
    "    #Rate\n",
    "    control_rate=control_numerator/control_denominator\n",
    "    var_rate=var_numerator/var_denominator\n",
    "    \n",
    "    #Variance\n",
    "\n",
    "    control_var=df.loc[1,numerator_sq]/control_denominator-control_rate**2\n",
    "    var_var=df.loc[0,numerator_sq]/var_denominator-var_rate**2\n",
    "    \n",
    "    #z score\n",
    "    z_score=(control_rate-var_rate)/math.sqrt(control_var/control_denominator+var_var/var_denominator)\n",
    "    \n",
    "    \n",
    "    #p value\n",
    "    p_value=scipy.stats.norm.sf(abs(z_score))\n",
    "    \n",
    "    \n",
    "    #lift\n",
    "    perc_lift=(var_rate-control_rate)/control_rate\n",
    "    abs_lift=(var_rate-control_rate)\n",
    "    \n",
    "    return (p_value,perc_lift,abs_lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_types=['SessionID','CusID']\n",
    "dic_rev_final={}\n",
    "\n",
    "\n",
    "for user_type in user_types:\n",
    "    print(user_type)\n",
    "    df_Result = pd.DataFrame(df_Rev.drop_duplicates([user_type,'ControlGroup']).groupby('ControlGroup')[user_type].count())\n",
    "              \n",
    "    df_Result.loc[1,'Rev']=sum(Control_Rev[Control_Rev<P1])\n",
    "    df_Result.loc[0,'Rev']=sum(Var_Rev[Var_Rev<P2])\n",
    "\n",
    "    df_Result.loc[1,'Rev_sq']=sum(Control_Rev[Control_Rev<P1]**2)\n",
    "    df_Result.loc[0,'Rev_sq']=sum(Var_Rev[Var_Rev<P2]**2)\n",
    "    \n",
    "    for index in df_Result.index:\n",
    "    \n",
    "        if index!=1:\n",
    "            df_each_group=df_Result\n",
    "            df_final=pd.DataFrame()\n",
    "            result=z_test_calculator_continuous(df_each_group,user_type,'Rev','Rev_sq')\n",
    "\n",
    "            dic_rev_final[user_type]= result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rev_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rev_final=pd.DataFrame(dic_rev_final).T\n",
    "dic_rev_final=dic_rev_final.rename(columns={0:'p_value',1:'perc_lift',2:'abs_lift'})\n",
    "dic_rev_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('3.3 Final_revenue_data_Test2.xlsx')\n",
    "dic_rev_final.to_excel(writer, sheet_name='revenue_data_Test2')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_data = df_Rev.copy()\n",
    "dic_rev_final_cuts_usertype = {}\n",
    "user_types = ['SessionID','CusID']\n",
    "cuts = ['CategoryID','VisitorTypeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_type in user_types:\n",
    "    print(user_type)\n",
    "    for cut in cuts:\n",
    "        print(cut)\n",
    " \n",
    "        for p in set(df_rev_data[cut]):\n",
    "\n",
    "            df_Rev_cut = df_rev_data[df_rev_data[cut]==p]\n",
    "            Control_Rev_cut=df_Rev_cut[df_Rev_cut['ControlGroup']==1]['TotalRevenue'].array\n",
    "            Var_Rev_cut=df_Rev_cut[df_Rev_cut['ControlGroup']==0]['TotalRevenue'].array\n",
    "           \n",
    "            df_Result_any = pd.DataFrame(df_Rev_cut.drop_duplicates([user_type,'ControlGroup']).groupby('ControlGroup')[user_type].count())\n",
    "            \n",
    "            df_Result_any.loc[1,'Rev']=sum(Control_Rev_cut)\n",
    "            df_Result_any.loc[0,'Rev']=sum(Var_Rev_cut)\n",
    "            df_Result_any.loc[1,'Rev_sq']=sum(Control_Rev_cut**2)\n",
    "            df_Result_any.loc[0,'Rev_sq']=sum(Var_Rev_cut**2)\n",
    "\n",
    "            for index in df_Result.index:\n",
    "\n",
    "                if index!=1:\n",
    "                    df_each_group=df_Result_any\n",
    "                    df_final=pd.DataFrame()\n",
    "                    result=z_test_calculator_continuous(df_each_group,user_type,'Rev','Rev_sq')\n",
    "\n",
    "                    dic_rev_final_cuts_usertype [user_type+'_'+cut+str(p)]= result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rev_final_cuts_usertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rev_final_cuts_usertype=pd.DataFrame(dic_rev_final_cuts_usertype).T\n",
    "dic_rev_final_cuts_usertype=dic_rev_final_cuts_usertype.rename(columns={0:'p_value',1:'perc_lift',2:'abs_lift'})\n",
    "dic_rev_final_cuts_usertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('3.4 Final_revenue_cuts_data_Test2.xlsx')\n",
    "dic_rev_final_cuts_usertype.to_excel(writer, sheet_name='revenue_cuts_data_Test2')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
